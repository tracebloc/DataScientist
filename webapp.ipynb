{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "agricultural-defendant",
   "metadata": {},
   "source": [
    "### Import some useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "secret-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import getpass, os\n",
    "import ast\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "downtown-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Token(username, password):\n",
    "    '''Function to get Token for username provided'''\n",
    "    try:\n",
    "        url = \"https://xray-backend.azurewebsites.net/api-token-auth/\"\n",
    "        r = requests.post(url, data = {\"username\": username, \"password\": password})\n",
    "\n",
    "        if r.status_code != 200:\n",
    "            print(\"###################################################\")\n",
    "            print(\"###################################################\")\n",
    "            print(\"Provide a valid username and password.....\")\n",
    "            print(\"###################################################\")\n",
    "            print(\"###################################################\")\n",
    "        else:\n",
    "\n",
    "            print(\"###################################################\")\n",
    "            print(\"###################################################\")\n",
    "            print(\"Authorized.....\")\n",
    "            print(\"###################################################\")\n",
    "            print(\"###################################################\")\n",
    "\n",
    "        token = json.loads(r.text)['token']\n",
    "    \n",
    "    except Exception as e:\n",
    "        \n",
    "        print(\"Error in logging in:: \" + str(e))\n",
    "        raise Exception(e)\n",
    "\n",
    "    return token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-perception",
   "metadata": {},
   "source": [
    "### Login with Datascientist Id and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "numeric-constant",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter UserID\n",
      "datascientist\n",
      "Enter password...\n",
      "········\n",
      "###################################################\n",
      "###################################################\n",
      "Authorized.....\n",
      "###################################################\n",
      "###################################################\n"
     ]
    }
   ],
   "source": [
    "token = \"\"\n",
    "while len(token) == 0:\n",
    "    \n",
    "    user = input(\"Enter UserID\\n\")\n",
    "    password = getpass.getpass(\"Enter password...\\n\")\n",
    "    token = get_Token(user,password)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-davis",
   "metadata": {},
   "source": [
    "### Enter Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "national-attribute",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provide parameters to train your model..\n",
      "###################################################\n",
      "###################################################\n",
      "Enter datasetId\n",
      " default: 0\t80\n",
      "Enter modelName\n",
      " default: model\tvggnet\n",
      "Enter optimizer\n",
      " default: adam\t\n",
      "Enter lossFunction\n",
      " default: binary_crossentropy\t\n",
      "Enter learningRate\n",
      " default: 0.001\t\n",
      "Enter epochs\n",
      " default: 1\t10\n",
      "Enter stepsPerEpoch\n",
      " default: None\t\n",
      "Enter initialEpoch\n",
      " default: 0\t\n",
      "Enter cycles\n",
      " default: 1\t2\n",
      "Enter validationSteps\n",
      " default: None\t\n",
      "Enter batchSize\n",
      " default: 16\t\n",
      "Enter featurewise_center\n",
      " default: False\t\n",
      "Enter samplewise_center\n",
      " default: False\t\n",
      "Enter featurewise_std_normalization\n",
      " default: False\t\n",
      "Enter samplewise_std_normalization\n",
      " default: False\t\n",
      "Enter zca_whitening\n",
      " default: False\t\n",
      "Enter rotation_range\n",
      " default: 0\t\n",
      "Enter width_shift_range\n",
      " default: 0.0\t\n",
      "Enter height_shift_range\n",
      " default: 0.0\t\n",
      "Enter brightness_range\n",
      " default: None\t\n",
      "Enter shear_range\n",
      " default: 0.0\t\n",
      "Enter zoom_range\n",
      " default: 0.0\t\n",
      "Enter channel_shift_range\n",
      " default: 0.0\t\n",
      "Enter fill_mode\n",
      " default: nearest\t\n",
      "Enter cval\n",
      " default: 0.0\t\n",
      "Enter horizontal_flip\n",
      " default: False\t\n",
      "Enter vertical_flip\n",
      " default: False\t\n",
      "Enter rescale\n",
      " default: None\t\n",
      "Enter data_format\n",
      " default: None\t\n",
      "Enter validation_split\n",
      " default: 0.1\t\n",
      "Enter dtype\n",
      " default: None\t\n",
      "Enter shuffle\n",
      " default: True\t\n",
      "Enter values for layers_non_trainable separated by comma\n",
      "Enter values for metrics separated by commaaccuracy\n",
      "201\n",
      "b'{\"id\":97,\"datasetId_id\":80,\"modelName\":\"9d017c0a-b3fa-44ed-9513-0aab175eddec_vggnet\",\"userId_id\":15,\"created_date\":\"2021-07-19T11:23:35.058061Z\",\"updated_date\":\"2021-07-19T11:23:35.055087Z\",\"totalParameter\":\"\",\"optimizer\":\"adam\",\"layersTrained\":\"\",\"callbacks\":\"\",\"lossFunction\":\"binary_crossentropy\",\"metrics\":\"[\\'accuracy\\']\",\"edges_involved\":\"[\\'19\\', \\'16\\', \\'18\\', \\'17\\']\",\"zca_epsilon\":\"\",\"data_format\":\"None\",\"dtype\":\"None\",\"fill_mode\":\"nearest\",\"brightness_range\":\"None\",\"featurewise_center\":false,\"samplewise_center\":false,\"featurewise_std_normalization\":false,\"samplewise_std_normalization\":false,\"zca_whitening\":false,\"horizontal_flip\":false,\"vertical_flip\":false,\"shuffle\":true,\"learningRate\":0.001,\"epochs\":10,\"stepsPerEpoch\":\"None\",\"initialEpoch\":0,\"cycles\":2,\"validationSteps\":\"None\",\"batchSize\":16,\"shear_range\":0.0,\"zoom_range\":0.0,\"channel_shift_range\":0.0,\"cval\":0.0,\"rescale\":\"None\",\"validation_split\":0.1,\"rotation_range\":0,\"width_shift_range\":0.0,\"height_shift_range\":0.0,\"status\":0}'\n"
     ]
    }
   ],
   "source": [
    "print(\"Provide parameters to train your model..\")\n",
    "print(\"###################################################\")\n",
    "print(\"###################################################\")\n",
    "\n",
    "parameters = {'message':'training',\n",
    "              \"datasetId\":0,\"modelName\":'model',\"optimizer\":'adam',\n",
    "              \"lossFunction\":'binary_crossentropy',\"learningRate\":0.001,\n",
    "              \"epochs\":1,\"stepsPerEpoch\":'None',\"initialEpoch\":0,\"cycles\":1,\n",
    "              \"validationSteps\":'None',\"batchSize\":16,\"featurewise_center\":False,\n",
    "              \"samplewise_center\":False,\"featurewise_std_normalization\":False,\n",
    "              \"samplewise_std_normalization\":False,\"zca_whitening\":False,\n",
    "              \"rotation_range\":0,\"width_shift_range\":0.0,\n",
    "              \"height_shift_range\":0.0,\"brightness_range\":'None',\n",
    "              \"shear_range\":0.0,\"zoom_range\":0.0,\"channel_shift_range\":0.0,\n",
    "              \"fill_mode\":\"nearest\",\"cval\":0.0,\"horizontal_flip\":False,\n",
    "              \"vertical_flip\":False,\"rescale\":'None',\"data_format\":'None',\n",
    "              \"validation_split\":0.1,\"dtype\":'None',\"shuffle\":True}\n",
    "\n",
    "#################################\n",
    "for i in parameters.keys():\n",
    "    inp = ''\n",
    "    if i != \"message\":\n",
    "        \n",
    "        inp = input(f\"Enter {i}\\n default: {parameters[i]}\\t\")\n",
    "        \n",
    "    if inp:\n",
    "        parameters[i] = inp\n",
    "###############################\n",
    "#get values for metrics and layers to be freezed from user\n",
    "\n",
    "excluded = {\"layers_non_trainable\":[],\"metrics\":[]}   \n",
    "\n",
    "\n",
    "for i in excluded.keys():\n",
    "    \n",
    "    inp = input(f\"Enter values for {i} separated by comma\")\n",
    "    for j in inp.split(','):\n",
    "        excluded[i].append(j)\n",
    "\n",
    "parameters.update(excluded)\n",
    "####################################\n",
    "\n",
    "#Insert all parameters in Experiment table   \n",
    "parameters['metrics'] = str(parameters['metrics'])\n",
    "#######################################################\n",
    "url = \"http://127.0.0.1:8000/experiments/\"\n",
    "# url = 'https://xray-backend.azurewebsites.net/experiments/'\n",
    "header = {'Authorization' : f\"Token {token}\"}\n",
    "re = requests.post(url,headers= header,data=parameters)\n",
    "print(re.status_code)\n",
    "print(re.content)\n",
    "\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-access",
   "metadata": {},
   "source": [
    "### Upload model file and weights to the server before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "meaning-professional",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure model file and weights are in current directory !\n",
      "###################################################\n",
      "###################################################\n",
      "Enter your model file name here eg: vggnet....\n",
      "vggnet\n",
      "###################################################\n",
      "###################################################\n",
      "###################################################\n",
      "###################################################\n",
      "Model file uploaded.....\n",
      "###################################################\n",
      "###################################################\n",
      "Weights uploaded....\n"
     ]
    }
   ],
   "source": [
    "body_unicode = re.content.decode('utf-8')\n",
    "content = json.loads(body_unicode)\n",
    "print(\"Make sure model file and weights are in current directory !\")\n",
    "print(\"###################################################\")\n",
    "print(\"###################################################\")\n",
    "model_name = input(\"Enter your model file name here eg: vggnet....\\n\")\n",
    "print(\"###################################################\")\n",
    "print(\"###################################################\")\n",
    "\n",
    "#Upload/Send model file to the server\n",
    "\n",
    "# url_model = 'http://127.0.0.1:8000/upload/'\n",
    "url_model = 'https://xray-backend.azurewebsites.net/upload/'\n",
    "header = {'Authorization' : f\"Token {token}\"}\n",
    "files = {'upload_file': open(f'{model_name}.py','rb')}\n",
    "values = {'type': \"model\",\"experimentId\": content['id']}\n",
    "r = requests.post(url_model, headers = header, files=files, data=values)\n",
    "if r.status_code == 200:\n",
    "    print(\"###################################################\")\n",
    "    print(\"###################################################\")\n",
    "    print(\"Model file uploaded.....\")\n",
    "else:\n",
    "    print(\"###################################################\")\n",
    "    print(\"###################################################\")\n",
    "    print(\"Error uploading....\")\n",
    "\n",
    "#Upload/Send model weights to the server\n",
    "# url_weights = 'http://127.0.0.1:8000/upload/'\n",
    "url_weights = 'https://xray-backend.azurewebsites.net/upload/'\n",
    "header = {'Authorization' : f\"Token {token}\"}\n",
    "files = {'upload_file': open(f'{model_name}_weights.pkl','rb')}\n",
    "values = {'type': \"weights\",\"experimentId\": content['id']}\n",
    "r = requests.post(url_weights, headers = header, files=files, data=values)\n",
    "if r.status_code == 200:\n",
    "    print(\"###################################################\")\n",
    "    print(\"###################################################\")\n",
    "    print(\"Weights uploaded....\")\n",
    "else:\n",
    "    print(\"###################################################\")\n",
    "    print(\"###################################################\")\n",
    "    print(\"Error uploading....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-cache",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-circular",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell for callbacks or leave the cell unrexecuted\n",
    "\n",
    "''' provide callbacks in the list below like: \n",
    "    my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]'''\n",
    "\n",
    "# my_callbacks = ['tf.keras.callbacks.EarlyStopping(patience=2)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-writing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dont run this cell incase my_callbacks is empty\n",
    "# parameters['callbacks'] = my_callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-collectible",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-studio",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-distribution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "annual-translator",
   "metadata": {},
   "source": [
    "### Send training plan to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fifteen-ceiling",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training request sent....\n",
      "Updated weights will be available to download once training completed\n"
     ]
    }
   ],
   "source": [
    "data = {\"experiment_id\":content['id']}\n",
    "#Send training request to server\n",
    "# url = \"http://127.0.0.1:8000/training/\"\n",
    "url = \"https://xray-backend.azurewebsites.net/training/\"\n",
    "header = {'Authorization' : f\"Token {token}\"}\n",
    "r = requests.post(url, headers = header, data = data )\n",
    "body_unicode = r.content.decode('utf-8')\n",
    "content = json.loads(body_unicode)\n",
    "print(content['message'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
